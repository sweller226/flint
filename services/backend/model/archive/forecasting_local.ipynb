{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6e31e4",
   "metadata": {},
   "source": [
    "# Flint — Local Forecasting Benchmark (Multi-Model)\n",
    "\n",
    "This notebook runs locally (macOS/Linux/Windows) and will:\n",
    "1. Load contract CSVs from the repo data folder\n",
    "2. Build leakage-safe train/val/test splits\n",
    "3. Benchmark multiple models (quick tune + shorter train)\n",
    "4. Pick the best model and train it longer\n",
    "5. Report: train/val curves, test curves, and direction confusion matrix + accuracy/precision/recall/F1\n",
    "\n",
    "Recommended: run from the repo root so paths auto-resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports + device\n",
    "import json, math, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "FEATURE_COLS = ['open', 'high', 'low', 'close', 'volume']\n",
    "CLOSE_IDX = FEATURE_COLS.index('close')\n",
    "\n",
    "def seed_all(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "USE_GPU = (device.type == 'cuda')\n",
    "PIN_MEMORY = USE_GPU\n",
    "NUM_WORKERS = 0  # macOS: keep 0 for stability; increase on Linux if desired\n",
    "\n",
    "if USE_GPU:\n",
    "    # Speed knobs (safe defaults)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print('device:', device)\n",
    "if USE_GPU:\n",
    "    print('gpu:', torch.cuda.get_device_name(0))\n",
    "\n",
    "def make_loader(dataset, *, batch_size: int, shuffle: bool, drop_last: bool) -> DataLoader:\n",
    "    # pin_memory + non_blocking transfers improve GPU input pipeline\n",
    "    kwargs = dict(num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    if NUM_WORKERS > 0:\n",
    "        kwargs['persistent_workers'] = True\n",
    "        kwargs['prefetch_factor'] = 2\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG (local) ===\n",
    "seed_all(42)\n",
    "\n",
    "def find_notebook_dir(notebook_name: str = 'forecasting_local.ipynb', start: Optional[Path] = None) -> Path:\n",
    "    \"\"\"Best-effort: find the directory containing this notebook by walking up from CWD.\"\"\"\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / notebook_name).exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "NOTEBOOK_DIR = find_notebook_dir()\n",
    "DATA_DIR = NOTEBOOK_DIR  # CSVs are expected to live next to this notebook\n",
    "ARTIFACTS_DIR = NOTEBOOK_DIR / 'artifacts_local'\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('NOTEBOOK_DIR:', NOTEBOOK_DIR)\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('ARTIFACTS_DIR:', ARTIFACTS_DIR)\n",
    "\n",
    "# Preprocessing\n",
    "LOG_VOLUME = True\n",
    "\n",
    "# Target mode: delta-from-last is usually much easier than absolute OHLCV\n",
    "TARGET_MODE = 'delta_last'  # 'delta_last' or 'absolute'\n",
    "\n",
    "# Data/windowing\n",
    "BATCH_SIZE = 32\n",
    "HORIZON = 60\n",
    "DAYS_PER_SAMPLE = 7\n",
    "STRIDE_DAYS = 1\n",
    "MIN_DAY_LEN_RATIO = 0.9\n",
    "TRAIN_FRAC, VAL_FRAC, TEST_FRAC = 0.8, 0.1, 0.1\n",
    "\n",
    "# Benchmark settings (fast-ish)\n",
    "BENCH_MODELS = ['direct_lstm', 'attn_lstm', 'cnn_lstm', 'seq2seq_lstm']\n",
    "BENCH_TUNE_TRIALS = 8\n",
    "BENCH_TUNE_EPOCHS = 3\n",
    "BENCH_FINAL_EPOCHS = 20\n",
    "\n",
    "# Best-model long training\n",
    "FINAL_EPOCHS = 80\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "MAX_TRAIN_BATCHES_PER_EPOCH = None  # None = full epoch; set int to cap\n",
    "\n",
    "required = ['df_h.csv','df_m.csv','df_u.csv','df_z.csv']\n",
    "missing = [f for f in required if not (DATA_DIR / f).exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing files in DATA_DIR={DATA_DIR}: {missing}\\n\"\n",
    "        \"Put df_h.csv/df_m.csv/df_u.csv/df_z.csv next to forecasting_local.ipynb, or change DATA_DIR.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading + datasets\n",
    "def load_contract_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    expected = {'ts_event','open','high','low','close','volume','contract_month'}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name} missing columns: {sorted(missing)}\")\n",
    "    df = df.copy()\n",
    "    df['ts_event'] = pd.to_datetime(df['ts_event'], errors='coerce')\n",
    "    df = df.dropna(subset=['ts_event']).sort_values('ts_event').reset_index(drop=True)\n",
    "    for col in FEATURE_COLS:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df = df.dropna(subset=FEATURE_COLS)\n",
    "    if LOG_VOLUME:\n",
    "        df['volume'] = np.log1p(np.maximum(df['volume'].to_numpy(dtype=np.float64), 0.0)).astype(np.float32)\n",
    "    for col in FEATURE_COLS:\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "    df['contract_month'] = df['contract_month'].astype(str)\n",
    "    return df\n",
    "\n",
    "def compute_median_trading_minutes_per_day(df: pd.DataFrame) -> int:\n",
    "    day_counts = df.groupby(df['ts_event'].dt.date).size().astype(int)\n",
    "    if day_counts.empty:\n",
    "        raise ValueError('No daily rows found')\n",
    "    median_count = int(day_counts.median())\n",
    "    if median_count <= 0:\n",
    "        raise ValueError('Median daily count is <= 0')\n",
    "    return median_count\n",
    "\n",
    "def build_day_segments(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    day_len: int,\n",
    "    min_day_len_ratio: float = 0.9,\n",
    ") -> Tuple[np.ndarray, List[Tuple[int,int]], List[pd.Timestamp]]:\n",
    "    if day_len <= 60:\n",
    "        raise ValueError('day_len must be > 60 to hold a 1-hour target')\n",
    "    df = df.sort_values('ts_event').reset_index(drop=True)\n",
    "    data = df[FEATURE_COLS].to_numpy(dtype=np.float32, copy=True)\n",
    "    groups = df.groupby(df['ts_event'].dt.date, sort=True)\n",
    "    day_segments: List[Tuple[int,int]] = []\n",
    "    day_starts: List[pd.Timestamp] = []\n",
    "    min_len = int(day_len * min_day_len_ratio)\n",
    "    for _, g in groups:\n",
    "        if len(g) < min_len:\n",
    "            continue\n",
    "        day_start_idx = int(g.index.min())\n",
    "        day_end_idx = int(g.index.max()) + 1\n",
    "        if (day_end_idx - day_start_idx) < day_len:\n",
    "            continue\n",
    "        seg_end = day_end_idx\n",
    "        seg_start = seg_end - day_len\n",
    "        day_segments.append((seg_start, seg_end))\n",
    "        day_starts.append(pd.Timestamp(g['ts_event'].iloc[0]))\n",
    "    if not day_segments:\n",
    "        raise ValueError('No valid day segments were created; check day_len/min_day_len_ratio')\n",
    "    return data, day_segments, day_starts\n",
    "\n",
    "class WeekToHourDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        contract_name: str,\n",
    "        data: np.ndarray,\n",
    "        day_segments: List[Tuple[int,int]],\n",
    "        week_starts: List[int],\n",
    "        day_len: int,\n",
    "        days_per_sample: int = 7,\n",
    "        horizon: int = 60,\n",
    "        mean: Optional[np.ndarray] = None,\n",
    "        std: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        self.contract_name = contract_name\n",
    "        self.data = data\n",
    "        self.day_segments = day_segments\n",
    "        self.week_starts = week_starts\n",
    "        self.day_len = day_len\n",
    "        self.days_per_sample = days_per_sample\n",
    "        self.horizon = horizon\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.total_len = self.days_per_sample * day_len\n",
    "        if self.total_len <= horizon:\n",
    "            raise ValueError('Total sample length must be > horizon')\n",
    "        self.input_len = self.total_len - horizon\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.week_starts)\n",
    "\n",
    "    def set_scaler(self, mean: np.ndarray, std: np.ndarray) -> None:\n",
    "        self.mean = mean.astype(np.float32)\n",
    "        self.std = std.astype(np.float32)\n",
    "\n",
    "    def _get_week_array(self, start_day_idx: int) -> np.ndarray:\n",
    "        segs = self.day_segments[start_day_idx : start_day_idx + self.days_per_sample]\n",
    "        return np.concatenate([self.data[s:e] for (s, e) in segs], axis=0)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        start_day = self.week_starts[idx]\n",
    "        seq = self._get_week_array(start_day)\n",
    "        x = seq[: self.input_len]\n",
    "        y = seq[self.input_len :]\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            x = (x - self.mean) / self.std\n",
    "            y = (y - self.mean) / self.std\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
    "\n",
    "def compute_global_scaler_from_train(train_datasets: Sequence[WeekToHourDataset], eps: float = 1e-6) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    sum_vec = np.zeros((len(FEATURE_COLS),), dtype=np.float64)\n",
    "    sumsq_vec = np.zeros((len(FEATURE_COLS),), dtype=np.float64)\n",
    "    count = 0\n",
    "    for ds in train_datasets:\n",
    "        for start_day in ds.week_starts:\n",
    "            seq = ds._get_week_array(start_day)\n",
    "            x = seq[: ds.input_len]\n",
    "            sum_vec += x.sum(axis=0)\n",
    "            sumsq_vec += (x * x).sum(axis=0)\n",
    "            count += x.shape[0]\n",
    "    if count == 0:\n",
    "        raise ValueError('No training rows to compute scaler')\n",
    "    mean = (sum_vec / count).astype(np.float32)\n",
    "    var = (sumsq_vec / count) - (mean.astype(np.float64) ** 2)\n",
    "    std = np.sqrt(np.maximum(var, 0.0)).astype(np.float32)\n",
    "    std = np.where(std < eps, np.float32(1.0), std)\n",
    "    return mean, std\n",
    "\n",
    "def build_datasets_for_contract(\n",
    "    contract_name: str,\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    day_len_override: Optional[int] = None,\n",
    "    days_per_sample: int = 7,\n",
    "    stride_days: int = 1,\n",
    "    horizon: int = 60,\n",
    "    min_day_len_ratio: float = 0.9,\n",
    "    train_frac: float = 0.8,\n",
    "    val_frac: float = 0.1,\n",
    "    test_frac: float = 0.1,\n",
    ") -> Dict[str, WeekToHourDataset]:\n",
    "    day_len = day_len_override or compute_median_trading_minutes_per_day(df)\n",
    "    data, day_segments, _ = build_day_segments(df, day_len=day_len, min_day_len_ratio=min_day_len_ratio)\n",
    "    n_days = len(day_segments)\n",
    "    train_day_end = max(days_per_sample, int(n_days * train_frac))\n",
    "    val_day_end = max(train_day_end + days_per_sample, int(n_days * (train_frac + val_frac)))\n",
    "    val_day_end = min(n_days, val_day_end)\n",
    "\n",
    "    def starts_in_range(day_start: int, day_end: int) -> List[int]:\n",
    "        last_start = day_end - days_per_sample\n",
    "        if last_start < day_start:\n",
    "            return []\n",
    "        return list(range(day_start, last_start + 1, stride_days))\n",
    "\n",
    "    train_starts = starts_in_range(0, train_day_end)\n",
    "    val_starts = starts_in_range(train_day_end, val_day_end)\n",
    "    test_starts = starts_in_range(val_day_end, n_days)\n",
    "    if len(train_starts) < 5 or len(val_starts) < 1 or len(test_starts) < 1:\n",
    "        raise ValueError(f'Not enough samples after split for {contract_name}: train={len(train_starts)} val={len(val_starts)} test={len(test_starts)}')\n",
    "\n",
    "    return {\n",
    "        'train': WeekToHourDataset(contract_name=contract_name, data=data, day_segments=day_segments, week_starts=train_starts, day_len=day_len, days_per_sample=days_per_sample, horizon=horizon),\n",
    "        'val': WeekToHourDataset(contract_name=contract_name, data=data, day_segments=day_segments, week_starts=val_starts, day_len=day_len, days_per_sample=days_per_sample, horizon=horizon),\n",
    "        'test': WeekToHourDataset(contract_name=contract_name, data=data, day_segments=day_segments, week_starts=test_starts, day_len=day_len, days_per_sample=days_per_sample, horizon=horizon),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7625e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build splits + global scaler\n",
    "files = {\n",
    "    'H': DATA_DIR / 'df_h.csv',\n",
    "    'M': DATA_DIR / 'df_m.csv',\n",
    "    'U': DATA_DIR / 'df_u.csv',\n",
    "    'Z': DATA_DIR / 'df_z.csv',\n",
    "}\n",
    "\n",
    "contract_dfs: Dict[str, pd.DataFrame] = {}\n",
    "median_day_lens: Dict[str, int] = {}\n",
    "for c, p in files.items():\n",
    "    df = load_contract_csv(p)\n",
    "    contract_dfs[c] = df\n",
    "    median_day_lens[c] = compute_median_trading_minutes_per_day(df)\n",
    "\n",
    "global_day_len = int(min(median_day_lens.values()))\n",
    "if global_day_len <= HORIZON:\n",
    "    raise ValueError(f'global_day_len ({global_day_len}) must be > horizon ({HORIZON})')\n",
    "print('median_day_lens:', median_day_lens, 'global_day_len:', global_day_len)\n",
    "\n",
    "contract_splits: Dict[str, Dict[str, WeekToHourDataset]] = {}\n",
    "for c, df in contract_dfs.items():\n",
    "    contract_splits[c] = build_datasets_for_contract(\n",
    "        c, df,\n",
    "        day_len_override=global_day_len,\n",
    "        days_per_sample=DAYS_PER_SAMPLE, stride_days=STRIDE_DAYS, horizon=HORIZON,\n",
    "        min_day_len_ratio=MIN_DAY_LEN_RATIO,\n",
    "        train_frac=TRAIN_FRAC, val_frac=VAL_FRAC, test_frac=TEST_FRAC,\n",
    "    )\n",
    "    ds = contract_splits[c]['train']\n",
    "    print(f\"{c}: train={len(contract_splits[c]['train'])} val={len(contract_splits[c]['val'])} test={len(contract_splits[c]['test'])} input_len={ds.input_len}\")\n",
    "\n",
    "train_datasets = [contract_splits[c]['train'] for c in contract_splits]\n",
    "mean, std = compute_global_scaler_from_train(train_datasets)\n",
    "for c in contract_splits:\n",
    "    for split_name in ('train','val','test'):\n",
    "        contract_splits[c][split_name].set_scaler(mean, std)\n",
    "print('global_scaler_mean:', {k: float(v) for k, v in zip(FEATURE_COLS, mean)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model zoo (modular) ---\n",
    "def build_seq2seq_lstm_forecaster(*, input_size: int = 5, hidden_size: int = 192, num_layers: int = 2, dropout: float = 0.1) -> nn.Module:\n",
    "    class Seq2SeqLSTMForecaster(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.encoder = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "            self.decoder = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "            self.proj = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        def forward(self, x, y=None, *, horizon: int = 60, teacher_forcing: bool = True):\n",
    "            _, (h, c) = self.encoder(x)\n",
    "            if teacher_forcing and y is not None:\n",
    "                last_x = x[:, -1:, :]\n",
    "                dec_in = torch.cat([last_x, y[:, :-1, :]], dim=1)\n",
    "                dec_out, _ = self.decoder(dec_in, (h, c))\n",
    "                return self.proj(dec_out)\n",
    "            preds = []\n",
    "            inp = x[:, -1:, :]\n",
    "            state = (h, c)\n",
    "            for _ in range(horizon):\n",
    "                dec_out, state = self.decoder(inp, state)\n",
    "                step = self.proj(dec_out)\n",
    "                preds.append(step)\n",
    "                inp = step\n",
    "            return torch.cat(preds, dim=1)\n",
    "    return Seq2SeqLSTMForecaster()\n",
    "\n",
    "def build_direct_lstm_forecaster(*, input_size: int = 5, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.1, horizon: int = 60, output_size: int = 5) -> nn.Module:\n",
    "    class DirectLSTMForecaster(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "            self.head = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, horizon * output_size))\n",
    "            self.horizon = horizon\n",
    "            self.output_size = output_size\n",
    "        def forward(self, x, y=None, *, horizon: Optional[int] = None, teacher_forcing: bool = True):\n",
    "            _out, (h, _c) = self.lstm(x)\n",
    "            last = h[-1]\n",
    "            hzn = int(horizon) if horizon is not None else self.horizon\n",
    "            return self.head(last).view(x.shape[0], hzn, self.output_size)\n",
    "    return DirectLSTMForecaster()\n",
    "\n",
    "def build_attn_lstm_forecaster(*, input_size: int = 5, hidden_size: int = 192, num_layers: int = 2, dropout: float = 0.1, horizon: int = 60, output_size: int = 5) -> nn.Module:\n",
    "    class AttnLSTMForecaster(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "            self.attn = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.Tanh(), nn.Linear(hidden_size, 1))\n",
    "            self.head = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Dropout(dropout), nn.Linear(hidden_size, horizon * output_size))\n",
    "            self.horizon = horizon\n",
    "            self.output_size = output_size\n",
    "        def forward(self, x, y=None, *, horizon: Optional[int] = None, teacher_forcing: bool = True):\n",
    "            out, _ = self.lstm(x)\n",
    "            scores = self.attn(out).squeeze(-1)\n",
    "            w = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "            ctx = (w * out).sum(dim=1)\n",
    "            hzn = int(horizon) if horizon is not None else self.horizon\n",
    "            return self.head(ctx).view(x.shape[0], hzn, self.output_size)\n",
    "    return AttnLSTMForecaster()\n",
    "\n",
    "def build_cnn_lstm_forecaster(*, input_size: int = 5, conv_channels: int = 64, hidden_size: int = 160, num_layers: int = 2, dropout: float = 0.1, horizon: int = 60, output_size: int = 5) -> nn.Module:\n",
    "    class CNNLSTMForecaster(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv1d(input_size, conv_channels, kernel_size=7, stride=2, padding=3), nn.ReLU(),\n",
    "                nn.Conv1d(conv_channels, conv_channels, kernel_size=5, stride=2, padding=2), nn.ReLU(),\n",
    "                nn.Conv1d(conv_channels, conv_channels, kernel_size=5, stride=2, padding=2), nn.ReLU(),\n",
    "            )\n",
    "            self.lstm = nn.LSTM(input_size=conv_channels, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "            self.head = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Dropout(dropout), nn.Linear(hidden_size, horizon * output_size))\n",
    "            self.horizon = horizon\n",
    "            self.output_size = output_size\n",
    "        def forward(self, x, y=None, *, horizon: Optional[int] = None, teacher_forcing: bool = True):\n",
    "            z = self.conv(x.transpose(1, 2)).transpose(1, 2)\n",
    "            _out, (h, _c) = self.lstm(z)\n",
    "            last = h[-1]\n",
    "            hzn = int(horizon) if horizon is not None else self.horizon\n",
    "            return self.head(last).view(x.shape[0], hzn, self.output_size)\n",
    "    return CNNLSTMForecaster()\n",
    "\n",
    "def build_model(*, name: str, horizon: int, output_size: int, hidden_size: int, num_layers: int, dropout: float) -> nn.Module:\n",
    "    n = name.strip().lower()\n",
    "    if n == 'direct_lstm':\n",
    "        return build_direct_lstm_forecaster(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, horizon=horizon, output_size=output_size)\n",
    "    if n == 'attn_lstm':\n",
    "        return build_attn_lstm_forecaster(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, horizon=horizon, output_size=output_size)\n",
    "    if n == 'cnn_lstm':\n",
    "        return build_cnn_lstm_forecaster(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, horizon=horizon, output_size=output_size)\n",
    "    if n == 'seq2seq_lstm':\n",
    "        return build_seq2seq_lstm_forecaster(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    raise ValueError(f'Unknown model: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ce799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training + eval utilities (delta targets + metrics)\n",
    "def _make_delta_targets(xb: torch.Tensor, yb_abs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    last_x = xb[:, -1:, :]\n",
    "    return (yb_abs - last_x), last_x\n",
    "\n",
    "def _delta_to_abs(last_x: torch.Tensor, y_delta: torch.Tensor) -> torch.Tensor:\n",
    "    return y_delta + last_x\n",
    "\n",
    "def _to_device(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.to(device, non_blocking=PIN_MEMORY)\n",
    "\n",
    "def evaluate_abs_mse(model: nn.Module, loader: DataLoader, device: torch.device, max_batches: Optional[int] = None) -> float:\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    losses: List[float] = []\n",
    "    with torch.no_grad():\n",
    "        for i, (xb, yb_abs) in enumerate(loader):\n",
    "            if max_batches is not None and i >= max_batches:\n",
    "                break\n",
    "            xb = _to_device(xb)\n",
    "            yb_abs = _to_device(yb_abs)\n",
    "            if TARGET_MODE == 'delta_last':\n",
    "                yb_delta, last_x = _make_delta_targets(xb, yb_abs)\n",
    "                pred_delta = model(xb, yb_delta, horizon=yb_delta.shape[1], teacher_forcing=True)\n",
    "                pred_abs = _delta_to_abs(last_x, pred_delta)\n",
    "            else:\n",
    "                pred_abs = model(xb, yb_abs, horizon=yb_abs.shape[1], teacher_forcing=True)\n",
    "            losses.append(loss_fn(pred_abs, yb_abs).item())\n",
    "    return float(np.mean(losses)) if losses else float('nan')\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    *,\n",
    "    train_loader: DataLoader,\n",
    "    val_loaders: Dict[str, DataLoader],\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    patience: int,\n",
    "    max_train_batches_per_epoch: Optional[int] = None,\n",
    "    min_delta: float = 1e-5,\n",
    ") -> Dict[str, object]:\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    hist = {\n",
    "        'train_delta_mse': [],\n",
    "        'val_abs_mse': {k: [] for k in val_loaders.keys()},\n",
    "        'val_abs_mean': [],\n",
    "        'lr': [],\n",
    "        'best_val': float('inf'),\n",
    "        'best_epoch': None,\n",
    "        'best_state_dict': None,\n",
    "    }\n",
    "    bad = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        batch_losses: List[float] = []\n",
    "        for bi, (xb, yb_abs) in enumerate(train_loader):\n",
    "            if max_train_batches_per_epoch is not None and bi >= max_train_batches_per_epoch:\n",
    "                break\n",
    "            xb = _to_device(xb)\n",
    "            yb_abs = _to_device(yb_abs)\n",
    "            if TARGET_MODE == 'delta_last':\n",
    "                yb_delta, _last_x = _make_delta_targets(xb, yb_abs)\n",
    "                y_train = yb_delta\n",
    "            else:\n",
    "                y_train = yb_abs\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, y_train, horizon=y_train.shape[1], teacher_forcing=True)\n",
    "            loss = loss_fn(pred, y_train)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            batch_losses.append(loss.item())\n",
    "        train_delta_mse = float(np.mean(batch_losses)) if batch_losses else float('nan')\n",
    "        hist['train_delta_mse'].append(train_delta_mse)\n",
    "        hist['lr'].append(float(opt.param_groups[0]['lr']))\n",
    "\n",
    "        val_report = {k: evaluate_abs_mse(model, v, device) for k, v in val_loaders.items()}\n",
    "        for k, v in val_report.items():\n",
    "            hist['val_abs_mse'][k].append(float(v))\n",
    "        val_mean = float(np.mean(list(val_report.values()))) if val_report else float('inf')\n",
    "        hist['val_abs_mean'].append(val_mean)\n",
    "        scheduler.step(val_mean)\n",
    "\n",
    "        msg = ' '.join([f\"{k}={v:.6f}\" for k, v in val_report.items()])\n",
    "        print(f\"epoch={epoch:03d}/{epochs} lr={opt.param_groups[0]['lr']:.2e} train_delta_mse={train_delta_mse:.6f} val_abs_mean={val_mean:.6f} {msg}\")\n",
    "\n",
    "        if val_mean + min_delta < hist['best_val']:\n",
    "            hist['best_val'] = val_mean\n",
    "            hist['best_epoch'] = epoch\n",
    "            hist['best_state_dict'] = {kk: vv.detach().cpu().clone() for kk, vv in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(f\"early_stop: epoch={epoch} best_epoch={hist['best_epoch']} best_val={hist['best_val']:.6f}\")\n",
    "                break\n",
    "\n",
    "    if hist['best_state_dict'] is not None:\n",
    "        model.load_state_dict(hist['best_state_dict'])\n",
    "    return hist\n",
    "\n",
    "def plot_curves(hist: Dict[str, object], title: str) -> None:\n",
    "    train = hist['train_delta_mse']\n",
    "    val = hist['val_abs_mse']\n",
    "    ep = np.arange(1, len(train) + 1)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(ep, train, label='train_delta_mse', linewidth=2)\n",
    "    for k, series in val.items():\n",
    "        plt.plot(ep, series, label=k.replace('val_', 'val_abs_'), linewidth=2)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE (normalized)')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def predict_one_unscaled(model: nn.Module, dataset: WeekToHourDataset, idx: int, device: torch.device) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    xb, yb_abs = dataset[idx]\n",
    "    xb_b = xb.unsqueeze(0)\n",
    "    yb_b = yb_abs.unsqueeze(0)\n",
    "    xb_b = _to_device(xb_b)\n",
    "    yb_b = _to_device(yb_b)\n",
    "    with torch.no_grad():\n",
    "        if TARGET_MODE == 'delta_last':\n",
    "            yb_delta, last_x = _make_delta_targets(xb_b, yb_b)\n",
    "            pred_delta = model(xb_b, yb_delta, horizon=yb_delta.shape[1], teacher_forcing=True)\n",
    "            pred_abs = _delta_to_abs(last_x, pred_delta)\n",
    "        else:\n",
    "            pred_abs = model(xb_b, yb_b, horizon=yb_b.shape[1], teacher_forcing=True)\n",
    "        pred_abs = pred_abs.squeeze(0).cpu().numpy().astype(np.float32)\n",
    "    actual = yb_abs.cpu().numpy().astype(np.float32)\n",
    "    if dataset.mean is not None and dataset.std is not None:\n",
    "        pred_abs = pred_abs * dataset.std + dataset.mean\n",
    "        actual = actual * dataset.std + dataset.mean\n",
    "    return pred_abs, actual\n",
    "\n",
    "def compute_test_feature_metrics(model: nn.Module, test_sets: Dict[str, WeekToHourDataset], device: torch.device, max_samples_per_contract: int = 200) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for c, ds in test_sets.items():\n",
    "        n = min(len(ds), max_samples_per_contract)\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        all_pred = []\n",
    "        all_true = []\n",
    "        for i in range(n):\n",
    "            pred, actual = predict_one_unscaled(model, ds, i, device)\n",
    "            all_pred.append(pred)\n",
    "            all_true.append(actual)\n",
    "        P = np.concatenate(all_pred, axis=0)\n",
    "        T = np.concatenate(all_true, axis=0)\n",
    "        err = P - T\n",
    "        mse = (err ** 2).mean(axis=0)\n",
    "        mae = np.abs(err).mean(axis=0)\n",
    "        rmse = np.sqrt(mse)\n",
    "        for j, col in enumerate(FEATURE_COLS):\n",
    "            rows.append({'contract': c, 'feature': col, 'mae': float(mae[j]), 'rmse': float(rmse[j]), 'mse': float(mse[j])})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def compute_direction_metrics(model: nn.Module, test_sets: Dict[str, WeekToHourDataset], device: torch.device, max_samples_per_contract: int = 200) -> Dict[str, object]:\n",
    "    y_true: List[int] = []\n",
    "    y_pred: List[int] = []\n",
    "    for c, ds in test_sets.items():\n",
    "        n = min(len(ds), max_samples_per_contract)\n",
    "        for i in range(n):\n",
    "            pred, actual = predict_one_unscaled(model, ds, i, device)\n",
    "            # direction relative to previous minute (seeded with last input close)\n",
    "            start_day = ds.week_starts[i]\n",
    "            seq = ds._get_week_array(start_day)\n",
    "            last_close = float(seq[ds.input_len - 1][CLOSE_IDX])\n",
    "            pred_close = pred[:, CLOSE_IDX]\n",
    "            act_close = actual[:, CLOSE_IDX]\n",
    "            pred_prev = np.concatenate([[last_close], pred_close[:-1]])\n",
    "            act_prev = np.concatenate([[last_close], act_close[:-1]])\n",
    "            pred_dir = (pred_close - pred_prev > 0).astype(np.int32)\n",
    "            act_dir = (act_close - act_prev > 0).astype(np.int32)\n",
    "            y_true.extend(act_dir.tolist())\n",
    "            y_pred.extend(pred_dir.tolist())\n",
    "    yt = np.array(y_true)\n",
    "    yp = np.array(y_pred)\n",
    "    cm = confusion_matrix(yt, yp, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = (tp + tn) / max(1, (tp + tn + fp + fn))\n",
    "    precision = tp / max(1, (tp + fp))\n",
    "    recall = tp / max(1, (tp + fn))\n",
    "    f1 = 2 * precision * recall / max(1e-12, (precision + recall))\n",
    "    return {\n",
    "        'cm': cm,\n",
    "        'accuracy': float(acc),\n",
    "        'precision_up': float(precision),\n",
    "        'recall_up': float(recall),\n",
    "        'f1_up': float(f1),\n",
    "        'n_labels': int(tp + tn + fp + fn),\n",
    "        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn),\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, title: str) -> None:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xticks([0,1], ['down/flat','up'])\n",
    "    plt.yticks([0,1], ['down/flat','up'])\n",
    "    for (i,j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha='center', va='center', color='black')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86128e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models -> pick best -> train longer -> report metrics\n",
    "def tune_params_for_model(model_name: str, rng_seed: int = 42) -> Dict[str, object]:\n",
    "    rng = random.Random(rng_seed)\n",
    "    hidden_sizes = [128, 192, 256]\n",
    "    num_layers_list = [1, 2, 3]\n",
    "    dropouts = [0.0, 0.1, 0.2]\n",
    "    lrs = [1e-3, 3e-4, 1e-4]\n",
    "\n",
    "    train_concat = ConcatDataset([contract_splits[c]['train'] for c in contract_splits])\n",
    "    train_loader = make_loader(train_concat, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    val_loaders = {f\"val_{c}\": make_loader(contract_splits[c]['val'], batch_size=BATCH_SIZE, shuffle=False, drop_last=False) for c in contract_splits}\n",
    "\n",
    "    trials = []\n",
    "    best = {'score': float('inf'), 'params': None, 'trial': None}\n",
    "\n",
    "    for trial in range(1, BENCH_TUNE_TRIALS + 1):\n",
    "        params = {\n",
    "            'hidden_size': rng.choice(hidden_sizes),\n",
    "            'num_layers': rng.choice(num_layers_list),\n",
    "            'dropout': rng.choice(dropouts),\n",
    "            'lr': rng.choice(lrs),\n",
    "        }\n",
    "        model = build_model(name=model_name, horizon=HORIZON, output_size=len(FEATURE_COLS), **params).to(device)\n",
    "        hist = train_model(\n",
    "            model,\n",
    "            train_loader=train_loader,\n",
    "            val_loaders=val_loaders,\n",
    "            epochs=BENCH_TUNE_EPOCHS,\n",
    "            lr=params['lr'],\n",
    "            device=device,\n",
    "            patience=max(2, min(4, BENCH_TUNE_EPOCHS)),\n",
    "            max_train_batches_per_epoch=200,\n",
    "        )\n",
    "        score = float(hist['best_val'])\n",
    "        trials.append({'trial': trial, 'score': score, **params})\n",
    "        print(f\"tune {model_name}: trial={trial}/{BENCH_TUNE_TRIALS} score={score:.6f} params={params}\")\n",
    "        if score < best['score']:\n",
    "            best = {'score': score, 'params': params, 'trial': trial}\n",
    "\n",
    "    df_trials = pd.DataFrame(trials).sort_values('score').reset_index(drop=True)\n",
    "    return {'best': best, 'trials_df': df_trials}\n",
    "\n",
    "def run_benchmark(models: List[str]) -> Tuple[pd.DataFrame, Dict[str, object]]:\n",
    "    results = []\n",
    "    artifacts = {}\n",
    "    for m in models:\n",
    "        print('\\n' + '='*80)\n",
    "        print('BENCH:', m)\n",
    "        print('='*80)\n",
    "        tune_out = tune_params_for_model(m)\n",
    "        best_params = tune_out['best']['params']\n",
    "        assert best_params is not None\n",
    "\n",
    "        model = build_model(name=m, horizon=HORIZON, output_size=len(FEATURE_COLS), **best_params).to(device)\n",
    "        train_concat = ConcatDataset([contract_splits[c]['train'] for c in contract_splits])\n",
    "        train_loader = make_loader(train_concat, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        val_loaders = {f\"val_{c}\": make_loader(contract_splits[c]['val'], batch_size=BATCH_SIZE, shuffle=False, drop_last=False) for c in contract_splits}\n",
    "\n",
    "        hist = train_model(\n",
    "            model,\n",
    "            train_loader=train_loader,\n",
    "            val_loaders=val_loaders,\n",
    "            epochs=BENCH_FINAL_EPOCHS,\n",
    "            lr=best_params['lr'],\n",
    "            device=device,\n",
    "            patience=min(EARLY_STOPPING_PATIENCE, 6),\n",
    "            max_train_batches_per_epoch=200,\n",
    "        )\n",
    "        val_score = float(hist['best_val'])\n",
    "\n",
    "        test_loaders = {f\"test_{c}\": make_loader(contract_splits[c]['test'], batch_size=BATCH_SIZE, shuffle=False, drop_last=False) for c in contract_splits}\n",
    "        test_report = {k: evaluate_abs_mse(model, v, device) for k, v in test_loaders.items()}\n",
    "        test_mean = float(np.mean(list(test_report.values())))\n",
    "        print('bench_test:', test_report, 'mean=', test_mean)\n",
    "\n",
    "        results.append({\n",
    "            'model': m,\n",
    "            'val_best_mean': val_score,\n",
    "            'test_mean': test_mean,\n",
    "            **{k: float(v) for k, v in test_report.items()},\n",
    "        })\n",
    "        artifacts[m] = {\n",
    "            'best_params': best_params,\n",
    "            'hist': hist,\n",
    "            'trials_df': tune_out['trials_df'],\n",
    "            'model_state': {k: v.detach().cpu().clone() for k, v in model.state_dict().items()},\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(['val_best_mean', 'test_mean']).reset_index(drop=True)\n",
    "    winner_name = str(df.iloc[0]['model'])\n",
    "    return df, {'winner_name': winner_name, **artifacts[winner_name]}\n",
    "\n",
    "bench_df, winner = run_benchmark(BENCH_MODELS)\n",
    "display(bench_df)\n",
    "print('WINNER:', winner['winner_name'], 'params:', winner['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208934e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model longer + full reporting\n",
    "best_model_name = winner['winner_name']\n",
    "best_params = winner['best_params']\n",
    "\n",
    "model = build_model(name=best_model_name, horizon=HORIZON, output_size=len(FEATURE_COLS), **best_params).to(device)\n",
    "\n",
    "train_concat = ConcatDataset([contract_splits[c]['train'] for c in contract_splits])\n",
    "train_loader = make_loader(train_concat, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loaders = {f\"val_{c}\": make_loader(contract_splits[c]['val'], batch_size=BATCH_SIZE, shuffle=False, drop_last=False) for c in contract_splits}\n",
    "\n",
    "final_hist = train_model(\n",
    "    model,\n",
    "    train_loader=train_loader,\n",
    "    val_loaders=val_loaders,\n",
    "    epochs=FINAL_EPOCHS,\n",
    "    lr=best_params['lr'],\n",
    "    device=device,\n",
    "    patience=EARLY_STOPPING_PATIENCE,\n",
    "    max_train_batches_per_epoch=MAX_TRAIN_BATCHES_PER_EPOCH,\n",
    ")\n",
    "\n",
    "plot_curves(final_hist, title=f\"Final Train/Val Curves — {best_model_name} (target={TARGET_MODE})\")\n",
    "\n",
    "# Test curves + metrics\n",
    "test_sets = {c: contract_splits[c]['test'] for c in contract_splits}\n",
    "\n",
    "def per_sample_mse(model: nn.Module, dataset: WeekToHourDataset, device: torch.device, max_samples: int = 200) -> np.ndarray:\n",
    "    n = min(len(dataset), max_samples)\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        pred, actual = predict_one_unscaled(model, dataset, i, device)\n",
    "        out.append(float(np.mean((pred - actual) ** 2)))\n",
    "    return np.array(out, dtype=np.float32)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for c, ds in test_sets.items():\n",
    "    mses = per_sample_mse(model, ds, device, max_samples=200)\n",
    "    plt.plot(np.arange(len(mses)), mses, label=f\"{c} per-sample MSE\")\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('MSE (original units)')\n",
    "plt.title('Test Per-Sample MSE Curves (subset)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "metrics_df = compute_test_feature_metrics(model, test_sets, device, max_samples_per_contract=150)\n",
    "display(metrics_df.groupby('feature')[['mae','rmse','mse']].mean().sort_values('rmse'))\n",
    "\n",
    "dir_metrics = compute_direction_metrics(model, test_sets, device, max_samples_per_contract=150)\n",
    "print('direction_metrics:', {k: v for k, v in dir_metrics.items() if k != 'cm'})\n",
    "plot_confusion_matrix(dir_metrics['cm'], title=f\"Close Direction Confusion Matrix — {best_model_name}\\nacc={dir_metrics['accuracy']:.3f} f1_up={dir_metrics['f1_up']:.3f}\")\n",
    "\n",
    "# Save artifacts\n",
    "ckpt_path = ARTIFACTS_DIR / 'best_forecaster.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_name': best_model_name,\n",
    "    'best_params': best_params,\n",
    "    'feature_cols': FEATURE_COLS,\n",
    "    'mean': mean,\n",
    "    'std': std,\n",
    "    'config': {\n",
    "        'target_mode': TARGET_MODE,\n",
    "        'log_volume': LOG_VOLUME,\n",
    "        'horizon': HORIZON,\n",
    "        'days_per_sample': DAYS_PER_SAMPLE,\n",
    "        'stride_days': STRIDE_DAYS,\n",
    "    }\n",
    "}, ckpt_path)\n",
    "print('saved:', ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
